{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn import metrics as sk_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from components.feature import *\n",
    "from components.dataset import raw_iterator, RawDataset\n",
    "from components.deepfm import DeepFM\n",
    "\n",
    "\n",
    "feat2idx =  {'user_id': (0, 1),\n",
    "             'keyword': (1, 2),\n",
    "             'sequence_keyword': (2, 3),\n",
    "             'search_source': (3, 4),\n",
    "             'session_id': (4, 5),\n",
    "             'item_id': (5, 6),\n",
    "             'show_cnt': (6, 7),\n",
    "             'click_cnt': (7, 8),\n",
    "             'play_cnt': (8, 9),\n",
    "             'like_cnt': (9, 10),\n",
    "             'follow_cnt': (10, 11),\n",
    "             'long_view_cnt': (11, 12),\n",
    "             'short_view_cnt': (12, 13),\n",
    "             'first_click': (13, 14),\n",
    "             'last_click': (14, 15),\n",
    "             'first_view': (15, 16),\n",
    "             'last_view': (16, 17),\n",
    "             'skip': (17, 18),\n",
    "             'exam': (18, 19),\n",
    "             'play_duration': (19, 20),\n",
    "             'slide_show': (20, 21),\n",
    "             'slide_click': (21, 22),\n",
    "             'pos': (22, 23),\n",
    "             'atlas_view_cnt': (23, 24),\n",
    "             'download_cnt': (24, 25),\n",
    "             'feed_model': (25, 26),\n",
    "             'p_date': (26, 27),\n",
    "             'product': (27, 28)}\n",
    "\n",
    "\n",
    "sparse_features = ['user_id', 'keyword', 'sequence_keyword', 'search_source', 'session_id', 'item_id',\n",
    "                   'first_click', 'last_click', 'first_view', 'last_view',\n",
    "                   'pos', 'feed_model', 'p_date', 'product']\n",
    "\n",
    "dense_features = ['show_cnt', 'click_cnt', 'play_cnt', 'like_cnt', 'follow_cnt', 'long_view_cnt',\n",
    "                  'short_view_cnt', 'slide_show', 'slide_click', 'atlas_view_cnt']\n",
    "\n",
    "sparse_embedding_feature = set([\"item_id\", \"user_id\", \"keyword\", \"session_id\", \"pos\"])\n",
    "\n",
    "data = pd.read_csv(\"data/raw/20210516\", sep=\"\\t\", dtype={feat: str for feat in sparse_features},\n",
    "                   error_bad_lines=False, quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "## 缺失值处理\n",
    "for feat in sparse_features + dense_features:\n",
    "    if feat in sparse_features:\n",
    "        data[feat] = data[feat].fillna(\"\")\n",
    "    else:\n",
    "        data[feat] = data[feat].fillna(0)\n",
    "\n",
    "## 离散特征编码\n",
    "sparse_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "data[sparse_features] = sparse_encoder.fit_transform(data[sparse_features])\n",
    "\n",
    "sparse_feature_info = {}\n",
    "for fname, word_list in zip(sparse_features, sparse_encoder.categories_):\n",
    "    vocab = {word: i for i, word in enumerate(np.concatenate((word_list, [\"__OOV__\"])))}\n",
    "    sparse_feature_info[fname] = {'index': feat2idx[fname],\n",
    "                                  'vocab': vocab,\n",
    "                                  'is_sparse': False if fname not in sparse_embedding_feature else True}\n",
    "dense_feature_info = {}\n",
    "for fname in dense_features:\n",
    "    dense_feature_info[fname] = feat2idx[fname]\n",
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id              109962\n",
      "keyword              189442\n",
      "sequence_keyword     2\n",
      "search_source        21\n",
      "session_id           339478\n",
      "item_id              3009648\n",
      "first_click          3\n",
      "last_click           3\n",
      "first_view           3\n",
      "last_view            3\n",
      "pos                  886\n",
      "feed_model           4\n",
      "p_date               2\n",
      "product              2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "feat2idx =  {'user_id': (0, 1),\n",
    "             'keyword': (1, 2),\n",
    "             'sequence_keyword': (2, 3),\n",
    "             'search_source': (3, 4),\n",
    "             'session_id': (4, 5),\n",
    "             'item_id': (5, 6),\n",
    "             'show_cnt': (6, 7),\n",
    "             'click_cnt': (7, 8),\n",
    "             'play_cnt': (8, 9),\n",
    "             'like_cnt': (9, 10),\n",
    "             'follow_cnt': (10, 11),\n",
    "             'long_view_cnt': (11, 12),\n",
    "             'short_view_cnt': (12, 13),\n",
    "             'first_click': (13, 14),\n",
    "             'last_click': (14, 15),\n",
    "             'first_view': (15, 16),\n",
    "             'last_view': (16, 17),\n",
    "             'skip': (17, 18),\n",
    "             'exam': (18, 19),\n",
    "             'play_duration': (19, 20),\n",
    "             'slide_show': (20, 21),\n",
    "             'slide_click': (21, 22),\n",
    "             'pos': (22, 23),\n",
    "             'atlas_view_cnt': (23, 24),\n",
    "             'download_cnt': (24, 25),\n",
    "             'feed_model': (25, 26),\n",
    "             'p_date': (26, 27),\n",
    "             'product': (27, 28)}\n",
    "for k, v in sparse_feature_info.items():\n",
    "    print(f\"{k:20}\", len(v['vocab']))\n",
    "json.dump(sparse_feature_info, open(\"data/vocab/20210516_sparse\", 'w'), indent=2)\n",
    "json.dump(dense_feature_info, open(\"data/vocab/20210516_dense\", 'w'), indent=2)\n",
    "json.dump(feat2idx, open(\"data/vocab/feat2idx\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset, BufferedShuffleDataset\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn import metrics as sk_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from components.feature import *\n",
    "from components.dataset import raw_iterator, RawDataset\n",
    "from components.deepfm import DeepFM\n",
    "\n",
    "sparse_feature_info = json.load(open(\"data/vocab/20210516_sparse\", 'r'))\n",
    "dense_feature_info = json.load(open(\"data/vocab/20210516_dense\", 'r'))\n",
    "feat2idx = json.load(open(\"data/vocab/feat2idx\", 'r'))\n",
    "sparse_embedding_feature = set([\"item_id\", \"user_id\", \"keyword\", \"session_id\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(\"data/raw\", file) for file in os.listdir(\"data/raw\") if file.startswith(\"20210516_\")]\n",
    "ds = RawDataset(files, sparse_feature_info, feat2idx[\"click_cnt\"][0])\n",
    "ds =  BufferedShuffleDataset(ds, 10000)\n",
    "loader = DataLoader(ds, batch_size=320, num_workers=3)\n",
    "\n",
    "sparse_feature_columns = [SparseFeat(name, v['index'], len(v['vocab']), 4, v['is_sparse'])\n",
    "                          for name, v in sparse_feature_info.items()]\n",
    "dense_feature_columns = [DenseFeat(name, index) for name, index in dense_feature_info.items()]\n",
    "\n",
    "model = DeepFM(sparse_feature_columns, dense_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:      192.43115234375, cost time: 17.666489124298096\n",
      "loss:   160.72447204589844, cost time: 15.696096181869507\n",
      "loss:    141.7527618408203, cost time: 13.71559762954712\n",
      "loss:   119.23631286621094, cost time: 14.293400764465332\n",
      "loss:    97.63081359863281, cost time: 17.603123664855957\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e88b604fc482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moptim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0moptim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moptim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "sparse_embedding_params = [list(getattr(model.embedding_dict, fname).parameters())[0]\n",
    "                           for fname in sparse_embedding_feature]\n",
    "dense_embedding_params = [list(getattr(model.embedding_dict, fname).parameters())[0]\n",
    "                          for fname in sparse_feature_info if fname not in sparse_embedding_feature]\n",
    "optim1 = torch.optim.SparseAdam(sparse_embedding_params)\n",
    "optim2 = torch.optim.Adam(dense_embedding_params)\n",
    "metric = sk_metrics.roc_auc_score\n",
    "loss_func = F.binary_cross_entropy\n",
    "\n",
    "i = 0\n",
    "pre = time.time()\n",
    "for batch in loader:\n",
    "    inputs, y = batch['features'], batch['label'].squeeze()\n",
    "\n",
    "    y_pred = model(inputs).squeeze()\n",
    "    optim1.zero_grad()\n",
    "    optim2.zero_grad()\n",
    "    loss = loss_func(y_pred, y,reduction='sum')\n",
    "    loss.backward()\n",
    "    optim1.step()\n",
    "    optim2.step()\n",
    "    i += 1\n",
    "    if i % 50 == 0:\n",
    "        now = time.time()\n",
    "        print(f\"loss: {loss.item():<20}, cost time: {now-pre:<20}\")\n",
    "        pre = now\n",
    "    # cpu: 大概15秒一个batch, 320个样本, 500w行大概跑78分钟\n",
    "    # gpu: torch.cuda.is_available() = False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.7452675722726655\n",
      "auc: 0.841092192053996\n",
      "auc: 0.7003917125086049\n",
      "auc: 0.889619487045374\n",
      "auc: 0.8051593753079122\n",
      "auc: 0.6835772357723577\n",
      "auc: 0.7735688671969556\n",
      "auc: 0.7829902366521595\n",
      "auc: 0.8357759999999999\n",
      "auc: 0.8384225217864925\n"
     ]
    }
   ],
   "source": [
    "ds_test = RawDataset([\"data/raw/20210517\"], sparse_feature_info, feat2idx[\"click_cnt\"][0])\n",
    "loader_test = DataLoader(ds_test, batch_size=1000, num_workers=0)\n",
    "for batch in loader_test:\n",
    "    inputs, y = batch['features'], batch['label'].squeeze()\n",
    "    y_pred = model(inputs).squeeze()\n",
    "    auc = metric(y.cpu().unsqueeze(dim=-1).data.numpy(), y_pred.cpu().unsqueeze(dim=-1).data.numpy())\n",
    "    print(f\"auc: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemingzhi_py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

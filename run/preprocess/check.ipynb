{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76851d1e-eba9-4510-b976-53112d733f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "root = \"/home/hemingzhi/.jupyter/ctr\"\n",
    "# table = \"xtr_base\"\n",
    "# date = \"20210527\"\n",
    "table = 'qp_pv_timeseq'\n",
    "date = '20210523'\n",
    "file = os.path.join(root, \"data\", table, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b45ccb-8f1b-4252-b8c9-4fa14f0a53fb",
   "metadata": {},
   "source": [
    "# 1. 看特征的缺失情况\n",
    "先用 head -n 200000 [file] > test，抽样观察。不要用完整数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d475e88-4d62-4bac-ac7b-c4af691ddf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword                        EXIST:1.0\n",
      "item_id                        EXIST:1.0\n",
      "show_cnt                       EXIST:1.0\n",
      "click_cnt                      EXIST:1.0\n",
      "play_cnt                       EXIST:1.0\n",
      "like_cnt                       EXIST:1.0\n",
      "follow_cnt                     EXIST:1.0\n",
      "long_view_cnt                  EXIST:1.0\n",
      "short_view_cnt                 EXIST:1.0\n",
      "first_click_cnt                EXIST:1.0\n",
      "last_click_cnt                 EXIST:1.0\n",
      "first_view_long_cnt            EXIST:1.0\n",
      "last_view_long_cnt             EXIST:1.0\n",
      "slide_show                     EXIST:1.0\n",
      "slide_click                    EXIST:1.0\n",
      "dtype                          EXIST:1.0\n",
      "now_show_cnt                   EXIST:0.995\n",
      "now_click_cnt                  EXIST:0.995\n",
      "now_play_cnt                   EXIST:0.995\n",
      "now_like_cnt                   EXIST:0.995\n",
      "now_follow_cnt                 EXIST:0.995\n",
      "now_long_view_cnt              EXIST:0.995\n",
      "now_short_view_cnt             EXIST:0.995\n",
      "now_first_click_cnt            EXIST:0.995\n",
      "now_last_click_cnt             EXIST:0.995\n",
      "now_first_view_long_cnt        EXIST:0.995\n",
      "now_last_view_long_cnt         EXIST:0.995\n",
      "now_slide_show                 EXIST:0.995\n",
      "now_slide_click                EXIST:0.995\n",
      "now_dtype                      EXIST:0.995\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(root, \"data\", table, \"test\"), sep='\\t')\n",
    "n = len(data)\n",
    "cols = []\n",
    "for fname in data.columns:\n",
    "    k = len(data[fname][~data[fname].isna()])\n",
    "#     if k / n >= 0.80:\n",
    "    print(f\"{fname:30} EXIST:{k/n}\")\n",
    "#         cols.append(fname)\n",
    "# print('\\n'.join([f\"    , {c}\" for c in cols]))\n",
    "# print('\\n'.join([f\"    , SUM({c}) AS {c}\" for c in cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6bc39-a527-4d9b-b294-b6e73ab19f84",
   "metadata": {},
   "source": [
    "# 2. 看有无重复的键对 (query, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c1b2e90-7425-43b6-8da1-b08fa624b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n"
     ]
    }
   ],
   "source": [
    "data['key'] = list(zip(data['keyword'], data['item_id']))\n",
    "dup = data['key'].duplicated()\n",
    "print(sum(dup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c12feb-ad11-4ed5-9d09-f33683012ca1",
   "metadata": {},
   "source": [
    "# 3. 看 query 数，item_id 数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91500c35-ed7b-4e2d-a1b3-e8cfb559c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data['keyword'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814e45e-4b87-4fb7-9c16-3a966b400f49",
   "metadata": {},
   "source": [
    "# 4. 查看样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1893a055-c1b1-4f39-9104-f478221da83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17193004\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "file = os.path.join(root, 'data', 'xtr_base', '20210527_filtered_train')\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02756508-52c1-4254-bdc8-e9e40f94d07b",
   "metadata": {},
   "source": [
    "# 5. 生成筛选数据，令eval集的 (query, item_id) 全在train集中出现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426c540-4fae-4a19-8e18-45efe5a97480",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"../../data/vocab/xtr_base_20210527_filtered.pkl\"\n",
    "with open(vocab, 'rb') as pkl:\n",
    "    sparse_feature_info = pickle.load(pkl)\n",
    "    # dense_feature_info = pickle.load(pkl)\n",
    "    # label_feature_info = pickle.load(pkl)\n",
    "kw_idx = sparse_feature_info['keyword']['index'][0]\n",
    "it_idx = sparse_feature_info['item_id']['index'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1d6aa8-99bd-47d7-975e-c35a304a6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_file_root = \"../../data/xtr_base/20210527_filtered_train_splits\"\n",
    "pre_files = sorted([os.path.join(pre_file_root, s) for s in os.listdir(pre_file_root)])[:16]\n",
    "\n",
    "pre_keys = set()\n",
    "for file in pre_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            feats = line.strip().split('\\t')\n",
    "            pre_keys.add((feats[kw_idx], feats[it_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702e67e-97ea-4821-a28d-ef0cccfbb3b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_file_root = \"../../data/xtr_base/20210528_filtered_train_splits\"\n",
    "post_files = sorted([os.path.join(post_file_root, s) for s in os.listdir(post_file_root)])\n",
    "\n",
    "save_path = \"../../data/xtr_base/20210528_keys_in_0527_eval_splits\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "end = False\n",
    "source_fp = 0\n",
    "output_fp = 0\n",
    "f = open(post_files[source_fp], 'r', encoding='utf-8')\n",
    "while not end:\n",
    "    fo = open(os.path.join(save_path, f\"20210528_keys_in_0527_{output_fp}\"), 'w', encoding='utf-8')\n",
    "    write_cnt = 0\n",
    "    while write_cnt < 200000:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            if source_fp + 1 < len(post_files):\n",
    "                print(\"DONE:\", post_files[source_fp], \"NOW_WRITING:\", os.path.join(save_path, f\"20210528_keys_in_0527_{output_fp}\"), \"write_cnt:\", write_cnt)\n",
    "                source_fp += 1\n",
    "                f.close()\n",
    "                f = open(post_files[source_fp], 'r', encoding='utf-8')\n",
    "                continue\n",
    "            else:\n",
    "                end = True\n",
    "                break\n",
    "        try:\n",
    "            feats = line.strip().split('\\t')\n",
    "            if (feats[kw_idx], feats[it_idx]) in pre_keys:\n",
    "                fo.write(line)\n",
    "                write_cnt += 1\n",
    "        except:\n",
    "            print(line)\n",
    "    output_fp += 1\n",
    "    fo.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9c433-0577-43f9-9d20-f4ee1da31756",
   "metadata": {},
   "source": [
    "# 6. 统计eval集相比训练集缺失多少(query, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feee5eba-526a-46f2-82e2-52a24f98ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"../../data/vocab/xtr_base_20210527_filtered.pkl\"\n",
    "with open(vocab, 'rb') as pkl:\n",
    "    sparse_feature_info = pickle.load(pkl)\n",
    "    # dense_feature_info = pickle.load(pkl)\n",
    "    # label_feature_info = pickle.load(pkl)\n",
    "kw_idx = sparse_feature_info['keyword']['index'][0]\n",
    "it_idx = sparse_feature_info['item_id']['index'][0]\n",
    "\n",
    "pre_file_root = \"../../data/xtr_base/20210527_filtered_train_splits\"\n",
    "pre_files = sorted([os.path.join(pre_file_root, s) for s in os.listdir(pre_file_root)])\n",
    "\n",
    "pre_keys = set()\n",
    "for file in pre_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            feats = line.strip().split('\\t')\n",
    "            pre_keys.add((feats[kw_idx], feats[it_idx]))\n",
    "\n",
    "post_file_root = \"../../data/xtr_base/20210528_filtered_train_splits\"\n",
    "post_files = sorted([os.path.join(post_file_root, s) for s in os.listdir(post_file_root)])\n",
    "\n",
    "post_keys = set()\n",
    "for file in post_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            feats = line.strip().split('\\t')\n",
    "            post_keys.add((feats[kw_idx], feats[it_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17de4b66-6b0e-4714-933e-d6e719490e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17193003\n",
      "1212304\n",
      "834823\n",
      "0.6886251303303462\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_keys))\n",
    "print(len(post_keys))\n",
    "print(len(post_keys & pre_keys))\n",
    "print(len(post_keys & pre_keys) / len(post_keys))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6_cuda",
   "language": "python",
   "name": "python3.6_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

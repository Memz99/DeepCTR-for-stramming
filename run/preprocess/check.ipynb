{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76851d1e-eba9-4510-b976-53112d733f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "root = \"/home/hemingzhi/.jupyter/ctr\"\n",
    "# table = \"xtr_base\"\n",
    "# date = \"20210527\"\n",
    "# table = 'qp_pv_timeseq'\n",
    "# date = '20210523'\n",
    "table = \"xtr_v3\"\n",
    "date = \"20210721\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b45ccb-8f1b-4252-b8c9-4fa14f0a53fb",
   "metadata": {},
   "source": [
    "# 1. 看特征的缺失情况\n",
    "先用 head -n 200000 [file] > test，抽样观察。不要用完整数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d475e88-4d62-4bac-ac7b-c4af691ddf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword                        EXIST:0.9999995341551975\n",
      "item_id                        EXIST:1.0\n",
      "show_cnt_7d                    EXIST:1.0\n",
      "click_cnt_7d                   EXIST:1.0\n",
      "play_cnt_7d                    EXIST:1.0\n",
      "like_cnt_7d                    EXIST:1.0\n",
      "follow_cnt_7d                  EXIST:1.0\n",
      "long_view_cnt_7d               EXIST:1.0\n",
      "short_view_cnt_7d              EXIST:1.0\n",
      "first_click_cnt_7d             EXIST:1.0\n",
      "last_click_cnt_7d              EXIST:1.0\n",
      "first_view_long_cnt_7d         EXIST:1.0\n",
      "last_view_long_cnt_7d          EXIST:1.0\n",
      "slide_show_7d                  EXIST:1.0\n",
      "slide_click_7d                 EXIST:1.0\n",
      "show_cnt_30d                   EXIST:1.0\n",
      "click_cnt_30d                  EXIST:1.0\n",
      "play_cnt_30d                   EXIST:1.0\n",
      "like_cnt_30d                   EXIST:1.0\n",
      "follow_cnt_30d                 EXIST:1.0\n",
      "long_view_cnt_30d              EXIST:1.0\n",
      "short_view_cnt_30d             EXIST:1.0\n",
      "first_click_cnt_30d            EXIST:1.0\n",
      "last_click_cnt_30d             EXIST:1.0\n",
      "first_view_long_cnt_30d        EXIST:1.0\n",
      "last_view_long_cnt_30d         EXIST:1.0\n",
      "slide_show_30d                 EXIST:1.0\n",
      "slide_click_30d                EXIST:1.0\n",
      "pv                             EXIST:1.0\n",
      "now_click_cnt_7d               EXIST:1.0\n",
      "now_long_view_cnt_7d           EXIST:1.0\n",
      "now_play_cnt_7d                EXIST:1.0\n",
      "now_show_cnt_7d                EXIST:1.0\n",
      "now_click_cnt_30d              EXIST:1.0\n",
      "now_long_view_cnt_30d          EXIST:1.0\n",
      "now_play_cnt_30d               EXIST:1.0\n",
      "now_show_cnt_30d               EXIST:1.0\n",
      "query_embed                    EXIST:1.0\n",
      "photo_embed                    EXIST:1.0\n",
      "se_p_7d_show_cnt               EXIST:1.0\n",
      "se_p_7d_click_cnt              EXIST:1.0\n",
      "se_p_7d_first_click_cnt        EXIST:1.0\n",
      "se_p_7d_last_click_cnt         EXIST:1.0\n",
      "se_p_7d_play_cnt               EXIST:1.0\n",
      "se_p_7d_long_view_cnt          EXIST:1.0\n",
      "se_p_7d_first_view_long_cnt    EXIST:1.0\n",
      "se_p_7d_last_view_long_cnt     EXIST:1.0\n",
      "se_p_7d_short_view_cnt         EXIST:1.0\n",
      "se_p_7d_follow_cnt             EXIST:1.0\n",
      "se_p_7d_like_cnt               EXIST:1.0\n",
      "se_p_7d_slide_show             EXIST:1.0\n",
      "se_p_7d_slide_click            EXIST:1.0\n",
      "qp_doc_bow_embedding_score     EXIST:1.0\n",
      "qp_doc_cqr_v2                  EXIST:1.0\n",
      "qp_doc_mixture_bwei            EXIST:1.0\n",
      "qp_doc_mixture_omit            EXIST:1.0\n",
      "qp_doc_omit_score              EXIST:1.0\n",
      "qp_doc_username_bwei           EXIST:1.0\n",
      "qp_doc_video_bwei              EXIST:1.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(root, \"data\", table, date), sep='\\t', error_bad_lines=False, quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "n = len(df)\n",
    "cols = []\n",
    "for fname in df.columns:\n",
    "    k = len(df[fname][~df[fname].isna()])\n",
    "#     if k / n >= 0.80:\n",
    "    print(f\"{fname:30} EXIST:{k/n}\")\n",
    "#         cols.append(fname)\n",
    "# print('\\n'.join([f\"    , {c}\" for c in cols]))\n",
    "# print('\\n'.join([f\"    , SUM({c}) AS {c}\" for c in cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d6f85a8-6418-4b69-a2a6-00c8706b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show = \"show_cnt_30d\"\n",
    "click = \"click_cnt_30d\"\n",
    "dff = df[['keyword', 'item_id', show, click, 'pv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e92692b-404a-488c-9f9c-9dd9b485edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "915a941b-fc77-4ea2-8395-453fb3d9c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1258094 samples with show cnt in [0, 10): rate=0.6472\n",
      "For the 2080542 samples with show cnt in [10, 20): rate=0.5111\n",
      "For the 2641645 samples with show cnt in [20, 30): rate=0.4366\n",
      "For the 3063803 samples with show cnt in [30, 40): rate=0.3896\n",
      "For the 3398786 samples with show cnt in [40, 50): rate=0.3571\n",
      "For the 3673227 samples with show cnt in [50, 60): rate=0.3333\n",
      "For the 3904358 samples with show cnt in [60, 70): rate=0.3152\n",
      "For the 4102697 samples with show cnt in [70, 80): rate=0.3009\n",
      "For the 4275009 samples with show cnt in [80, 90): rate=0.2894\n",
      "For the 4426027 samples with show cnt in [90, 100): rate=0.2799\n",
      "For the 4560134 samples with show cnt in [100, 110): rate=0.2719\n",
      "For the 4679297 samples with show cnt in [110, 120): rate=0.2651\n",
      "For the 4786881 samples with show cnt in [120, 130): rate=0.2593\n",
      "For the 4883080 samples with show cnt in [130, 140): rate=0.2542\n",
      "For the 4970442 samples with show cnt in [140, 150): rate=0.2498\n",
      "For the 5049860 samples with show cnt in [150, 160): rate=0.2459\n",
      "For the 5122702 samples with show cnt in [160, 170): rate=0.2425\n",
      "For the 5188873 samples with show cnt in [170, 180): rate=0.2394\n",
      "For the 5249787 samples with show cnt in [180, 190): rate=0.2367\n",
      "For the 5305551 samples with show cnt in [190, 200): rate=0.2342\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    left, right = i*10, (i+1) * 10\n",
    "    show_cond = np.logical_and(0 <= dff[show], dff[show] < right)\n",
    "    show_click_cond = np.logical_and(show_cond, dff[click] <= 0)\n",
    "    rate = sum(show_click_cond) / sum(show_cond)\n",
    "    print(f\"For the {sum(show_cond)} samples with show cnt in [{left}, {right}): rate={rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43ca963-b02a-40c5-8777-8248bef10c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dff[show] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70e2ac5d-e59e-4e52-a521-d7d7bab4bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682286"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.logical_and(0 < dff[show], dff[show] <= 5)\n",
    "ind = np.logical_and(ind, dff['pv'] > 100)\n",
    "dfff = dff[ind]\n",
    "# ((dff[ind]['pv'] / 10).round() * 10).value_counts().to_dict()\n",
    "# (dfff[click] / dfff[show]).round(1).value_counts().to_dict()\n",
    "# (dfff[click] / dfff[show]).mean()\n",
    "len(dfff['keyword'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6bc39-a527-4d9b-b294-b6e73ab19f84",
   "metadata": {},
   "source": [
    "# 2. 看有无重复的键对 (query, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1b2e90-7425-43b6-8da1-b08fa624b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df['key'] = list(zip(df['keyword'], df['item_id']))\n",
    "dup = df['key'].duplicated()\n",
    "print(sum(dup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c12feb-ad11-4ed5-9d09-f33683012ca1",
   "metadata": {},
   "source": [
    "# 3. 看 query 数，item_id 数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91500c35-ed7b-4e2d-a1b3-e8cfb559c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21168542\n",
      "0.03509325299777377\n",
      "0.5809665115339545\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df['keyword'].unique()) / len(df))\n",
    "print(len(df['item_id'].unique()) / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814e45e-4b87-4fb7-9c16-3a966b400f49",
   "metadata": {},
   "source": [
    "# 4. 查看样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893a055-c1b1-4f39-9104-f478221da83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "file = os.path.join(root, 'data', 'xtr_base', '20210527_filtered_train')\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02756508-52c1-4254-bdc8-e9e40f94d07b",
   "metadata": {},
   "source": [
    "# 5. 生成筛选数据，令eval集的 (query, item_id) 全在train集中出现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426c540-4fae-4a19-8e18-45efe5a97480",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"../../data/vocab/xtr_base_20210608_filtered.pkl\"\n",
    "with open(vocab, 'rb') as pkl:\n",
    "    sparse_feature_info = pickle.load(pkl)\n",
    "    # dense_feature_info = pickle.load(pkl)\n",
    "    # label_feature_info = pickle.load(pkl)\n",
    "kw_idx = sparse_feature_info['keyword']['index'][0]\n",
    "it_idx = sparse_feature_info['item_id']['index'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d6aa8-99bd-47d7-975e-c35a304a6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_file_root = \"../../data/xtr_base/20210608_filtered_train_splits\"\n",
    "pre_files = sorted([os.path.join(pre_file_root, s) for s in os.listdir(pre_file_root)])\n",
    "\n",
    "pre_keys = set()\n",
    "for file in pre_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            feats = line.strip().split('\\t')\n",
    "            pre_keys.add((feats[kw_idx], feats[it_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702e67e-97ea-4821-a28d-ef0cccfbb3b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_file_root = \"../../data/xtr_base/20210609_filtered_train_splits\"\n",
    "post_files = sorted([os.path.join(post_file_root, s) for s in os.listdir(post_file_root)])\n",
    "\n",
    "save_path = \"../../data/xtr_base/20210609_keys_in_0608_eval_splits\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "end = False\n",
    "source_fp = 0\n",
    "output_fp = 0\n",
    "f = open(post_files[source_fp], 'r', encoding='utf-8')\n",
    "while not end:\n",
    "    fo = open(os.path.join(save_path, f\"20210609_keys_in_0608_{output_fp}\"), 'w', encoding='utf-8')\n",
    "    write_cnt = 0\n",
    "    while write_cnt < 200000:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            if source_fp + 1 < len(post_files):\n",
    "                print(\"DONE:\", post_files[source_fp], \"NOW_WRITING:\", os.path.join(save_path, f\"20210609_keys_in_0608_{output_fp}\"), \"write_cnt:\", write_cnt)\n",
    "                source_fp += 1\n",
    "                f.close()\n",
    "                f = open(post_files[source_fp], 'r', encoding='utf-8')\n",
    "                continue\n",
    "            else:\n",
    "                end = True\n",
    "                break\n",
    "        try:\n",
    "            feats = line.strip().split('\\t')\n",
    "            if (feats[kw_idx], feats[it_idx]) in pre_keys:\n",
    "                fo.write(line)\n",
    "                write_cnt += 1\n",
    "        except:\n",
    "            print(line)\n",
    "    output_fp += 1\n",
    "    fo.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9c433-0577-43f9-9d20-f4ee1da31756",
   "metadata": {},
   "source": [
    "# 6. 统计eval集相比训练集缺失多少(query, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee5eba-526a-46f2-82e2-52a24f98ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"../../data/vocab/xtr_base_20210527_filtered.pkl\"\n",
    "with open(vocab, 'rb') as pkl:\n",
    "    sparse_feature_info = pickle.load(pkl)\n",
    "    # dense_feature_info = pickle.load(pkl)\n",
    "    # label_feature_info = pickle.load(pkl)\n",
    "kw_idx = sparse_feature_info['keyword']['index'][0]\n",
    "it_idx = sparse_feature_info['item_id']['index'][0]\n",
    "\n",
    "pre_file_root = \"../../data/xtr_base/20210527_filtered_train_splits\"\n",
    "pre_files = sorted([os.path.join(pre_file_root, s) for s in os.listdir(pre_file_root)])\n",
    "\n",
    "pre_keys = set()\n",
    "for file in pre_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            feats = line.strip().split('\\t')\n",
    "            pre_keys.add((feats[kw_idx], feats[it_idx]))\n",
    "\n",
    "post_file_root = \"../../data/xtr_base/20210528_filtered_train_splits\"\n",
    "post_files = sorted([os.path.join(post_file_root, s) for s in os.listdir(post_file_root)])\n",
    "\n",
    "post_keys = set()\n",
    "for file in post_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            feats = line.strip().split('\\t')\n",
    "            post_keys.add((feats[kw_idx], feats[it_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de4b66-6b0e-4714-933e-d6e719490e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pre_keys))\n",
    "print(len(post_keys))\n",
    "print(len(post_keys & pre_keys))\n",
    "print(len(post_keys & pre_keys) / len(post_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d8e6f-d01e-46ab-a231-1cc5ab5c1b68",
   "metadata": {},
   "source": [
    "# 7. 查看标签分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8175163d-2115-4831-bca6-f30f5e53dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join(root, \"data\", table, date), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7202dc9-414b-4b50-b28c-59f610322792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0       3476394\n",
       "0.5        361536\n",
       "2.0        102269\n",
       "1.5         70680\n",
       "inf          6993\n",
       "3.0          6399\n",
       "4.0          1435\n",
       "2.5          1271\n",
       "5.0           271\n",
       "3.5           140\n",
       "6.0           133\n",
       "7.0            46\n",
       "8.0            20\n",
       "4.5            14\n",
       "5.5            13\n",
       "9.0            13\n",
       "10.0           10\n",
       "11.0            6\n",
       "16.0            4\n",
       "6.5             4\n",
       "14.0            4\n",
       "7.5             3\n",
       "12.0            3\n",
       "13.0            3\n",
       "359.0           2\n",
       "19.0            2\n",
       "360.0           2\n",
       "26.0            2\n",
       "99.0            2\n",
       "195.0           2\n",
       "166.0           1\n",
       "265.0           1\n",
       "803.5           1\n",
       "247.5           1\n",
       "228.0           1\n",
       "1045.0          1\n",
       "227.5           1\n",
       "200.0           1\n",
       "168.0           1\n",
       "1605.0          1\n",
       "20.0            1\n",
       "374.0           1\n",
       "100.5           1\n",
       "99.5            1\n",
       "8.5             1\n",
       "87.0            1\n",
       "64.5            1\n",
       "54.5            1\n",
       "36.5            1\n",
       "14.5            1\n",
       "358.0           1\n",
       "18.0            1\n",
       "372.0           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = df['show_cnt_30d'] <= 2\n",
    "dff = df[ind]\n",
    "(dff['click_cnt_30d'] / dff['show_cnt_30d']).round(2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caaa21e7-ce87-4a09-bd67-c64af091fc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    1208633\n",
       "1.000000     551483\n",
       "0.500000     319798\n",
       "0.333333      42221\n",
       "0.666667      23480\n",
       "             ...   \n",
       "0.409091          1\n",
       "0.476190          1\n",
       "0.034483          1\n",
       "0.518519          1\n",
       "0.809524          1\n",
       "Length: 169, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dff['long_view_cnt_30d'] / dff['play_cnt_30d']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6886f062-e06e-4248-9527-47a10ca7550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dff['click_rate'] = (df['click_cnt_30d'] / df['show_cnt_30d'])\n",
    "dff[df['show_cnt_30d'] == 0]['click_rate'] = 0 \n",
    "dff = dff[~dff['click_rate'].isna()]\n",
    "# dff['click_rate'].round(2).value_counts().to_dict()\n",
    "# dff['combo'] = list(zip(dff['show_cnt'], dff['click_cnt']))\n",
    "# dff['combo'].value_counts().to_dict()\n",
    "ctr_mean = dff['click_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb0037f-49ed-4bfe-9fa3-b1cf39b775e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.logical_or(df['show_cnt_30d'] > 0, df['play_cnt_30d'] > 0)\n",
    "dff = df[ind]\n",
    "dff['lvtr'] = dff['long_view_cnt_30d'] / dff['play_cnt_30d']\n",
    "dff = dff[~dff['lvtr'].isna()]\n",
    "# dfff['lvtr'].round(2).value_counts().to_dict()\n",
    "lvtr_mean = dff['lvtr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0155c0-85e9-4580-9667-c15f74f14dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctr: 0.46797196359379817\n",
      "lvtr: 0.3470034887590561\n"
     ]
    }
   ],
   "source": [
    "print('ctr:', ctr_mean)\n",
    "print('lvtr:', lvtr_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6_cuda",
   "language": "python",
   "name": "python3.6_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
